{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from numpy import nan\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn import cross_validation\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn import decomposition\n",
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set the global default size of matplotlib figures\n",
    "#plt.rc('figure', figsize=(10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('./Data/ML Data Collection.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scalar = preprocessing.MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "#Mapping priority list into numbers\n",
    "priority_list = sorted(train_data['Priority'].unique())\n",
    "\n",
    "float_list = [float(i) for i in range(0,len(priority_list))]\n",
    "priority_mapping = dict(zip(priority_list,float_list))\n",
    "train_data['priority_val'] = train_data['Priority'].map(priority_mapping)\n",
    "\n",
    "train_data['priority_val'] = (scalar.fit_transform(train_data['priority_val'].reshape(-1, 1))).ravel([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# APT normalization\n",
    "train_data['APT'] = (scalar.fit_transform(train_data['APT'].reshape(-1, 1))).ravel([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TSLR normalization\n",
    "train_data['TSLR'] = (scalar.fit_transform(train_data['TSLR'].reshape(-1, 1))).ravel([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check if 'Calls from Customer' needs to be normalized\n",
    "floatCallsArray =  np.asarray([float(i) for i in train_data['Calls from Customer']])\n",
    "train_data['Calls from Customer'] = (scalar.fit_transform(floatCallsArray.reshape(-1, 1))).ravel([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check if 'Number of Info to SAP from last TSLR' needs to be normalized\n",
    "floatNumInfoArray =  np.asarray([float(i) for i in train_data['Number of Info to SAP from last TSLR']])\n",
    "train_data['Number of Info to SAP from last TSLR'] = (scalar.fit_transform(floatNumInfoArray.reshape(-1, 1))).ravel([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check if 'Frequent changes in processor' needs to be normalized - might not be, need to check the whole data\n",
    "floatFreqChangeArray =  np.asarray([float(i) for i in train_data['Frequent changes in processor']])\n",
    "train_data['Frequent changes in processor'] = (scalar.fit_transform(floatFreqChangeArray.reshape(-1, 1))).ravel([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check if 'Number of Processors' needs to be normalized - might not be, need to check the whole data\n",
    "floatNumProcArray =  np.asarray([float(i) for i in train_data['Number of Processors']])\n",
    "train_data['Number of Processors'] = (scalar.fit_transform(floatNumProcArray.reshape(-1, 1))).ravel([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Mapping callback list into numbers\n",
    "#callback_list = sorted(train_data['Customer call back request'].unique())\n",
    "#callback_mapping = dict(zip(callback_list,range(0,len(callback_list))))\n",
    "#train_data['callback_val'] = train_data['Customer call back request'].map(callback_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Mapping core business list into numbers\n",
    "core_business_list = sorted(train_data['Core Business affected?'].unique())\n",
    "core_business_list.remove(nan)\n",
    "core_business_mapping = dict(zip(core_business_list,range(0,len(core_business_list))))\n",
    "train_data['core_business_val'] = train_data['Core Business affected?'].map(core_business_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data['core_business_val'] = train_data['core_business_val'].fillna(train_data['core_business_val'].median())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Mapping Go live list into numbers\n",
    "go_live_list = sorted(train_data['Go live Affected?'].unique())\n",
    "go_live_list.remove(nan)\n",
    "go_live_mapping = dict(zip(go_live_list,range(0,len(go_live_list))))\n",
    "train_data['go_live_val'] = train_data['Go live Affected?'].map(go_live_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data['go_live_val'] = train_data['go_live_val'].fillna(train_data['go_live_val'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Either normalize or remove Num of users affected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Mapping Work around list into numbers\n",
    "work_around_list = sorted(train_data['Work around available?'].unique())\n",
    "work_around_list.remove(nan)\n",
    "work_around_mapping = dict(zip(work_around_list,range(0,len(work_around_list))))\n",
    "train_data['work_around_val'] = train_data['Work around available?'].map(work_around_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data['work_around_val'] = train_data['work_around_val'].fillna(train_data['work_around_val'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Mapping escalation states into numbers\n",
    "escStages = sorted(train_data['Stage of Escalation'].unique())\n",
    "states_mapping = dict(zip(escStages,range(0,len(escStages))))\n",
    "train_data['escStages_val'] = train_data['Stage of Escalation'].map(states_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = train_data.drop(['Stage of Escalation', 'Priority', 'Customer call back request', 'Core Business affected?',\n",
    "                             'Go live Affected?', 'Work around available?'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = train_data.drop(['Num of users affected', 'Business Impact mentioned?'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#useful\n",
    "#train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(229L, 10L) (113L, 10L) (229L, 1L) (113L, 1L)\n"
     ]
    }
   ],
   "source": [
    "train_values = train_data.values\n",
    "X = train_values[:,:-1]\n",
    "Y = train_values[:,-1:]\n",
    "\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X,Y, test_size=0.33, random_state=0)\n",
    "print X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#rf = RandomForestClassifier(n_estimators=800,max_depth=50)\n",
    "rf = RandomForestClassifier(n_estimators=870, min_samples_leaf =8, n_jobs = -1, max_depth=12)\n",
    "rf.fit(X_train,y_train.ravel([1]))\n",
    "\n",
    "predicted_Y = rf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pca = decomposition.RandomizedPCA(n_components=3)\n",
    "#pca.fit(X_train)\n",
    "#X_train_pca = pca.transform(X_train)\n",
    "#x_test_pca = pca.transform(X_test)\n",
    "\n",
    "#svc = svm.SVC(kernel='rbf', C=1e9, gamma=1e3)\n",
    "#svc.fit(X_train,y_train.ravel([1]))\n",
    "#svc.fit(X_train_pca,y_train.ravel([1]))\n",
    "\n",
    "#predicted_svc = svc.predict(x_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.471615720524\n",
      "0.269242096187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Prajeen\\_Workstation\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:756: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n"
     ]
    }
   ],
   "source": [
    "#useful\n",
    "print rf.score(X_train,y_train)\n",
    "y_test_ravel = y_test.ravel([1])\n",
    "#print y_test_ravel,'\\n',predicted_Y\n",
    "\n",
    "#print 'x'*25\n",
    "\n",
    "#print svc.score(X_train_pca,y_train)\n",
    "#y_test_ravel = y_test.ravel([1])\n",
    "#print y_test_ravel,'\\n',predicted_svc\n",
    "\n",
    "print(metrics.f1_score(y_test_ravel, predicted_Y))\n",
    "#print(metrics.f1_score(y_test_ravel, predicted_svc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[20  8  7  4  2  0]\n",
      " [ 1  4  7  4  2  0]\n",
      " [ 1  2  0  0  0  0]\n",
      " [ 0  2  1  2  2  0]\n",
      " [ 0  3  1  4  2  3]\n",
      " [ 0  5  4  3  8 11]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print metrics.confusion_matrix(predicted_Y,y_test_ravel)\n",
    "#print metrics.confusion_matrix(predicted_kn,y_test_ravel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.91      0.49      0.63        41\n",
      "        1.0       0.17      0.22      0.19        18\n",
      "        2.0       0.00      0.00      0.00         3\n",
      "        3.0       0.12      0.29      0.17         7\n",
      "        4.0       0.12      0.15      0.14        13\n",
      "        5.0       0.79      0.35      0.49        31\n",
      "\n",
      "avg / total       0.59      0.35      0.42       113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print metrics.classification_report(predicted_Y,y_test_ravel)\n",
    "#print metrics.classification_report(predicted_kn,y_test_ravel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print to the file\n",
    "fileName = 'algoResult.txt'\n",
    "#initialRead =  open(fileName)\n",
    "#print initialRead.read()\n",
    "\n",
    "file =  open(fileName, 'w')\n",
    "file.truncate()\n",
    "\n",
    "for i in range(predicted_Y.size):\n",
    "    file.write(repr(int(predicted_Y[i]))+','+'\\n')\n",
    "    \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 929,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Notes\n",
    "# do confusion_matrix and classification_report from 4.3 -- done\n",
    "# implement train_test_split from 4.3 , check also 6.1 -- done\n",
    "# implement 4.3 Exercise: Model Selection via Validation -- done\n",
    "# implement 5.1 PCA and SVM (also from 7.1) - done\n",
    "\n",
    "# implement GridSearchCV from 6.2 and 7.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
